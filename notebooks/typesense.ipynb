{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Typesense Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, build typesense docker `docker-compose -up`\n",
    "\n",
    "Then run `crate_schema.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..') # add parent folder path\n",
    "from typesense_test.create_schema import client, schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_deleted': 2222}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.collections['targets'].documents.delete({'filter_by': 'concept_id: >=0'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../lib/artifacts/dicts/sources.pickle', 'rb') as handle:\n",
    "    sources_dict = pickle.load(handle)\n",
    "with open('../lib/artifacts/dicts/targets.pickle', 'rb') as handle:\n",
    "    targets_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean source descriptions prior to quering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "for k,v in sources_dict.items():\n",
    "    sources_dict[k] = \" \".join(re.sub('[!,*)@#%(&$_?.^\"]', ' ', v).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dict = [{\"concept_id\": k, \"target\": v} for k, v in targets_dict.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'HUC-OFALMOLOGY UVEITES'),\n",
       " (1, 'Here-oftalmologia'),\n",
       " (2, 'HECE-OFTALMOLOGIA CIR Blanket'),\n",
       " (3, 'Huc-Oftalmology Contactology'),\n",
       " (4, 'Huc-Oftalmology Contactology')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sources_dict.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'Uveitis and Ocular Inflammatory Disease Ophthalmology'),\n",
       " (1, 'Ophthalmology'),\n",
       " (2, 'Retina Ophthalmology'),\n",
       " (3, 'Ophthalmology'),\n",
       " (4, 'Corneal and Contact Management Optometrist')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(targets_dict.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load typesense with target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'success': True}, {'success': True}, {'success': True}, {'success': True}, {'success': True}]\n"
     ]
    }
   ],
   "source": [
    "client_response = client.collections['targets'].documents.import_(target_dict, {'action': 'upsert'}, batch_size=10000)\n",
    "print(client_response[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test top1, top5 and top10 recall on 2222 test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "\n",
    "def test_func(parameters):\n",
    "\n",
    "    total = len(sources_dict)\n",
    "    top1 = 0\n",
    "    top5 = 0\n",
    "    top10 = 0\n",
    "\n",
    "    # Track Encoding Time\n",
    "    start = time()\n",
    "\n",
    "    for i in range(total):\n",
    "        query = sources_dict[i]\n",
    "\n",
    "        search_parameters = {\"q\": query}\n",
    "        search_parameters.update(parameters)\n",
    "\n",
    "        results = client.collections[\"targets\"].documents.search(search_parameters)\n",
    "        matches = [i[\"document\"][\"concept_id\"] for i in results[\"hits\"]]\n",
    "        if i == matches[0]:\n",
    "            top1 += 1\n",
    "        if i in matches[:5]:\n",
    "            top5 += 1\n",
    "        if i in matches[:10]:\n",
    "            top10 += 1\n",
    "\n",
    "    # Compute time\n",
    "    end = time()\n",
    "    elapsed_seconds = end - start\n",
    "\n",
    "    print(\n",
    "        f\"top1: {top1/total:.2%}, top5: {top5/total:.2%}, top10: {top10/total:.2%}, n_tests: {total}, elapsed_seconds: {elapsed_seconds}, preds_per_second_X1000: {total/elapsed_seconds/1000}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By setting a high k and a high flat_search_cutoff we can force it to use brute-force search, which is much better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1: 49.05%, top5: 72.05%, top10: 77.86%, n_tests: 2222, elapsed_seconds: 35.875524044036865, preds_per_second_X1000: 0.06193637749437517\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    \"query_by\": \"embedding\",\n",
    "    \"vector_query\": \"embedding:([],k:1000,distance_threshold:1.00,flat_search_cutoff:1000)\",\n",
    "}\n",
    "test_func(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this is a bit sketchy, since it depends on K (which is the number of retrieved items). If we set K to 10 and maintain the high cutoff the results are poorer because it is not using brute-force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1: 42.35%, top5: 60.76%, top10: 65.17%, n_tests: 2222, elapsed_seconds: 34.33804202079773, preds_per_second_X1000: 0.06470957192766517\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    \"query_by\": \"embedding\",\n",
    "    \"vector_query\": \"embedding:([],k:10,distance_threshold:1.00,flat_search_cutoff:1000)\",\n",
    "}\n",
    "test_func(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, HNSW still has some parameters that are not accessible through this API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One option is to do hybrid search, with vector and word based search. The weight for each component is controled by a single `alpha` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1: 48.69%, top5: 73.04%, top10: 78.94%, n_tests: 2222, elapsed_seconds: 33.37315487861633, preds_per_second_X1000: 0.0665804598960386\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    \"query_by\": \"embedding,target\",\n",
    "    \"vector_query\": \"embedding:([],k:1000,distance_threshold:1.00,flat_search_cutoff:1000,alpha:0.7)\",\n",
    "}\n",
    "test_func(parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vocab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
