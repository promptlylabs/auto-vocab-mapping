{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categories for centroid tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_dict = dict(zip(s2c[\"source_vocabulary_id\"].unique(), range(s2c[\"source_vocabulary_id\"].unique().shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2c.loc[:, 'category'] = s2c['source_vocabulary_id'].map(categ_dict)\n",
    "s2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = np.array(s2c['category'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean pooling centroid computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_centroid(vectors, categories, category):\n",
    "    indeces = np.where(categories == category)\n",
    "    selected_vectors = vectors.take(indeces[0], axis=0)\n",
    "    return np.mean(selected_vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = {}\n",
    "\n",
    "for cat in sorted(np.unique(categories)):\n",
    "    centroids[cat] = compute_centroid(targets_emb, categories, cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = np.array([v for k, v in centroids.items()])\n",
    "len(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_pcs = compute_pca(targets_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca(pcs=targets_pcs, colors=categories, names=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources_pcs = compute_pca(centroids)\n",
    "plot_pca(pcs=sources_pcs, colors=sorted(np.unique(categories)), names=sorted(np.unique(categories)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of hits in top1 and top2 centroids test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_centroid = 0 \n",
    "top2_hit = 0\n",
    "for i in range(total):\n",
    "    # Compute distances\n",
    "    source_example = sources_emb[i]\n",
    "    distance, index = norml2_innerproduct(centroids, source_example)\n",
    "\n",
    "    if index[0][0] == categories[i]:\n",
    "        correct_centroid += 1\n",
    "    if categories[i] in index[0][:2]:\n",
    "        top2_hit += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(correct_centroid/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top2_hit/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If we count the number of singular hits for each category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "correct_category = 0 \n",
    "\n",
    "for i in range(total):\n",
    "    # Compute distances\n",
    "    source_example = sources_emb[i]\n",
    "    distance, index = norml2_innerproduct(targets_emb, source_example)\n",
    "    most_frequent_cat = mode(categories.take(index[0][:50])).mode\n",
    "\n",
    "    if most_frequent_cat == categories[i]:\n",
    "        correct_category += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_category/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_models_centroid(models: list, sources: list, targets: list, categories, centroids):\n",
    "    \n",
    "    # Store results\n",
    "    results = []\n",
    "\n",
    "    for plm in tqdm(models, desc=\"Testing models: \"):\n",
    "\n",
    "        # Track Results\n",
    "        correct_centroid = 0\n",
    "        top1 = 0\n",
    "        top5 = 0\n",
    "        top10 = 0\n",
    "        total = len(sources)\n",
    "\n",
    "        # Load Model\n",
    "        needs_remote_code = \"no\"\n",
    "        try:\n",
    "            model = SentenceTransformer(plm, trust_remote_code = False)\n",
    "        except ValueError:\n",
    "            model = SentenceTransformer(plm, trust_remote_code = True)\n",
    "            needs_remote_code = \"yes\"\n",
    "\n",
    "        # Encode\n",
    "        sources_emb = model.encode(sources, normalize_embeddings=True)\n",
    "        targets_emb = model.encode(targets, normalize_embeddings=True)\n",
    "        \n",
    "        # NOTE: Centroid computation would enter here\n",
    "        centroid_emb = centroids\n",
    "\n",
    "        start = time()\n",
    "        for i in tqdm(range(total), leave=False, desc=\"Computing dinstances: \"):\n",
    "\n",
    "            # Compute distances\n",
    "            source_example = sources_emb[i]\n",
    "            distance, index = norml2_innerproduct(centroid_emb, source_example)\n",
    "            infered_category = index[0][0]\n",
    "            if infered_category == categories[i]:\n",
    "                correct_centroid += 1\n",
    "            \n",
    "            # Search within the restricted space\n",
    "            indeces = np.where(categories == infered_category)\n",
    "            selected_vectors = targets_emb.take(indeces[0], axis=0)\n",
    "            indeces_map = dict(zip(range(selected_vectors.shape[0]), indeces))\n",
    "\n",
    "            distance, index = norml2_innerproduct(selected_vectors, source_example)\n",
    "            # Retrieve the real indeces\n",
    "            index2 = [indeces_map(_) for _ in index[0]]\n",
    "\n",
    "            # Check matches\n",
    "            if i == index2[0]:\n",
    "                top1 += 1\n",
    "                top5 += 1\n",
    "                top10 += 1\n",
    "            elif i in index2[:5]:\n",
    "                top5 += 1\n",
    "                top10 += 1\n",
    "            elif i in index2[:10]:\n",
    "                top10 += 1\n",
    "        end = time()\n",
    "        elapsed_seconds = end - start\n",
    "\n",
    "        results.append(f\"\"\"\n",
    "                        plm: {plm};\n",
    "                        needs remote code: {needs_remote_code};\n",
    "                        Correct_centroid: {correct_centroid/total:.2%};\n",
    "                        Top 1 match: {top1/total:.2%};\n",
    "                        Top 5 match: {top5/total:.2%};\n",
    "                        Top 10 match: {top10/total:.2%};\n",
    "                        Total number of tests: {len(sources)},\n",
    "                        Elapsed seconds: {elapsed_seconds};\n",
    "                        Predictions per second X 1000: {len(sources)/elapsed_seconds/1000:.2}\n",
    "                        \"\"\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_models = [\"mixedbread-ai/mxbai-embed-large-v1\", \n",
    "                  \"intfloat/multilingual-e5-small\",\n",
    "                  \"intfloat/multilingual-e5-large\",\n",
    "                  \"sentence-transformers/all-MiniLM-L6-v2\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test_models(list_of_models, sources, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(_) for _ in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test number of hits in each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_models_centroid(models: list, sources: list, targets: list, categories, centroids):\n",
    "    \n",
    "    # Store results\n",
    "    results = []\n",
    "\n",
    "    for plm in tqdm(models, desc=\"Testing models: \"):\n",
    "\n",
    "        # Encode\n",
    "        needs_remote_code = \"no\"\n",
    "        try:\n",
    "            model = SentenceTransformer(plm, trust_remote_code = False)\n",
    "        except ValueError:\n",
    "            model = SentenceTransformer(plm, trust_remote_code = True)\n",
    "            needs_remote_code = \"yes\"\n",
    "\n",
    "        sources_emb = model.encode(sources, normalize_embeddings=True)\n",
    "        targets_emb = model.encode(targets, normalize_embeddings=True)\n",
    "        \n",
    "        # o calculo dos centroids entraria aqui\n",
    "        centroid_emb = centroids\n",
    "\n",
    "        # counts\n",
    "        correct_category = 0\n",
    "        top1 = 0\n",
    "        top5 = 0\n",
    "        top10 = 0\n",
    "        total = len(sources)\n",
    "        \n",
    "        start = time()\n",
    "        for i in tqdm(range(total), leave=False, desc=\"Computing dinstances: \"):\n",
    "            \n",
    "            # Compute distances\n",
    "            source_example = sources_emb[i]\n",
    "            distance, index = compute_distance(targets_emb, source_example)\n",
    "            most_frequent_cat = mode(categories.take(index[0][:50])).mode\n",
    "\n",
    "            if most_frequent_cat == categories[i]:\n",
    "                correct_category += 1\n",
    "\n",
    "            # Search within the restricted space\n",
    "            indeces = np.where(categories == most_frequent_cat)\n",
    "            selected_vectors = targets_emb.take(indeces[0], axis=0)\n",
    "            indeces_map = dict(zip(range(selected_vectors.shape[0]), indeces))\n",
    "\n",
    "            distance, index = compute_distance(selected_vectors, source_example)\n",
    "            # Retrieve the real indeces\n",
    "            index2 = [indeces_map(_) for _ in index[0]]\n",
    "\n",
    "            # Check matches\n",
    "            if i == index2[0]:\n",
    "                top1 += 1\n",
    "                top5 += 1\n",
    "                top10 += 1\n",
    "            elif i in index2[:5]:\n",
    "                top5 += 1\n",
    "                top10 += 1\n",
    "            elif i in index2[:10]:\n",
    "                top10 += 1\n",
    "        end = time()\n",
    "        elapsed_seconds = end - start\n",
    "\n",
    "        results.append(f\"\"\"\n",
    "                        plm: {plm};\n",
    "                        needs remote code: {needs_remote_code};\n",
    "                        Correct_centroid: {correct_category/total:.2%};\n",
    "                        Top 1 match: {top1/total:.2%};\n",
    "                        Top 5 match: {top5/total:.2%};\n",
    "                        Top 10 match: {top10/total:.2%};\n",
    "                        Total number of tests: {len(sources)},\n",
    "                        Elapsed seconds: {elapsed_seconds};\n",
    "                        Predictions per second X 1000: {len(sources)/elapsed_seconds/1000:.2}\n",
    "                        \"\"\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_models = [\"microsoft/Multilingual-MiniLM-L12-H384\", \n",
    "                  'intfloat/multilingual-e5-small',\n",
    "                  \"sentence-transformers/all-MiniLM-L6-v2\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test_models(list_of_models, sources, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(_) for _ in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
