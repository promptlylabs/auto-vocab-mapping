{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Vocab Mapping\n",
    "___\n",
    "\n",
    "## POC 1 - Vector Space Search\n",
    "\n",
    "For the first POC I'll focus on source and target descriptions only. So I just need previously matched sources and targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read CHUC example files and see what's in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chuc_s_df = pd.read_csv(\"../lib/data/raw/source_codes_description/chuc/analises_cod_acto.csv\")\n",
    "chuc_s2c_df = pd.read_csv(\"../lib/data/raw/source_to_concept/chuc/source_to_standard_analises_cod_acto.csv\")\n",
    "concept = pd.read_csv(\"../lib/data/raw/vocabularies/CONCEPT.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept['concept_id'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_dtype = concept['concept_id'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make dict to map quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dict = dict(zip(concept['concept_id'], concept['concept_name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here I need concept_id and concept_name to map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chuc_s_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are translations. We're not going into this for now. A separate exploration will be carried out for this topic alone. We could fine-tune our own medical data whichi has its specificities. We'll need: \n",
    "- Medical terms translation\n",
    "- Acronym desambiguation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chuc_s2c_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here I need the source code description and the target concept id. This is what well need in large quantities if we want to train a translator or a classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chuc_df = chuc_s2c_df[[\"source_code_description\", \"target_concept_id\"]]\n",
    "chuc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map target concepts and check missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chuc_df.loc[:, 'concept_name'] = chuc_df['target_concept_id'].astype(set_dtype).map(target_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chuc_df[chuc_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chuc_s2c = chuc_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chuc_s2c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = chuc_s2c[\"source_code_description\"].tolist()\n",
    "sources[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = chuc_s2c[\"concept_name\"].tolist()\n",
    "targets[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some lm are trained as seq2seq and need the `query` and `passage` prefixes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [(\"query: \" + i) for i in sources]\n",
    "targets = [(\"query: \" + i) for i in targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sources) == len(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode texts into fixed sized mean pooled vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode using torch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class TextEncoder:\n",
    "    def __init__(self, model):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "        self.model = AutoModel.from_pretrained(model)\n",
    "\n",
    "    def encode(self, texts):\n",
    "        # Tokenize the input texts\n",
    "        batch_dict = self.tokenizer(texts,\n",
    "                                    max_length=512,\n",
    "                                    padding=True,\n",
    "                                    truncation=True,\n",
    "                                    return_tensors='pt')\n",
    "        outputs = self.model(**batch_dict)\n",
    "        embeddings = TextEncoder.__average_pool(\n",
    "            outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "\n",
    "        # Normalize embeddings\n",
    "        embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "        return np.array(embeddings.detach(), dtype=np.float32)\n",
    "\n",
    "    @staticmethod\n",
    "    def __average_pool(last_hidden_states: Tensor,\n",
    "                       attention_mask: Tensor) -> Tensor:\n",
    "        last_hidden = last_hidden_states.masked_fill(\n",
    "            ~attention_mask[..., None].bool(), 0.0)\n",
    "        return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'intfloat/multilingual-e5-small'\n",
    "embeddings = TextEncoder(model_name).encode(sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, sentence_transformers disables the parallelism to avoid any hidden deadlock that would be hard to debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('intfloat/multilingual-e5-small')\n",
    "sources_emb = model.encode(sources, normalize_embeddings=True)\n",
    "targets_emb = model.encode(targets, normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence_transformer's implementation is faster than my manual approach so I'll stick to that. If in any case it has some incopatibility with a newer model I'll use mine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything seems fine with the resulting vector space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n",
    "Exploring projections in the vector space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def compute_pca(vectors):\n",
    "    pca = PCA()\n",
    "    pca.fit(vectors)\n",
    "    pcs = pca.transform(vectors)\n",
    "    return pcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def plot_pca(pcs, colors, names, title='PCA'):\n",
    "    fig = px.scatter_3d(x=pcs[:,0],\n",
    "                    y=pcs[:,1],\n",
    "                    z=pcs[:,2],\n",
    "                    color=colors,\n",
    "                    size_max=18,\n",
    "                    opacity=0.7,\n",
    "                    hover_name=names,\n",
    "                    labels={\n",
    "                        \"x\":\"PC1\",\n",
    "                        \"y\":\"PC2\",\n",
    "                        \"z\":\"PC3\"\n",
    "                    })\n",
    "\n",
    "    fig.update_layout(title=title)\n",
    "    fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "    fig.update_layout(showlegend=False)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = np.vstack([sources_emb, targets_emb])\n",
    "print(stacked.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_pcs = compute_pca(stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "names = sources + targets\n",
    "sources_ids = [\"source\" for _ in sources]\n",
    "targets_ids = [\"target\" for _ in targets]\n",
    "group_names = sources_ids + targets_ids\n",
    "# colors\n",
    "color_by_group = sources_ids + targets_ids\n",
    "individual_names = targets + targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca(pcs=stacked_pcs, colors=color_by_group, names=group_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clusters relate to the languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matches (sources - targets) should be closer if we color them the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca(pcs=stacked_pcs[:20], colors=individual_names[:20], names=individual_names[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dict = dict(zip(range(len(sources)), sources))\n",
    "target_dict = dict(zip(range(len(targets)), targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_number = np.random.choice(len(sources), 1, replace=True)[0]\n",
    "source_example = sources_emb[rand_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f' source: {source_dict[rand_number]};\\n target: {target_dict[rand_number]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test distance: Compute nomalized L2 inner product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "\n",
    "def norml2_innerproduct(feature_space, query):\n",
    "\n",
    "    index = faiss.index_factory(\n",
    "        feature_space.shape[1], \"Flat\", faiss.METRIC_INNER_PRODUCT)\n",
    "    faiss.normalize_L2(feature_space)\n",
    "    index.add(feature_space)\n",
    "    distance, index = index.search(np.array([query]), k=feature_space.shape[0])\n",
    "\n",
    "    return distance, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance, index = norml2_innerproduct(targets_emb, source_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f' source: {source_dict[rand_number]};\\n target: {target_dict[index[0][0]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1 = 0\n",
    "top5 = 0\n",
    "top10 = 0\n",
    "total = len(sources)\n",
    "for i in range(total):\n",
    "    source_example = sources_emb[i]\n",
    "    distance, index = norml2_innerproduct(targets_emb, source_example)\n",
    "    \n",
    "    if i == index[0][0]:\n",
    "        top1+=1\n",
    "        top5+=1\n",
    "        top10+=1\n",
    "    elif i in index[0][:5]:\n",
    "        top5+=1\n",
    "        top10+=1\n",
    "    elif i in index[0][:10]:\n",
    "        top10+=1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "      Top 1 match: {top1/total:.2%};\n",
    "      Top 5 match: {top5/total:.2%};ok\n",
    "      Top 10 match: {top10/total:.2%};\n",
    "      Total number of tests: {len(sources)}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expand the number of examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..') # add parent folder path\n",
    "from data_preprocessors import RawDataProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_folders = [\"../lib/data/raw/source_to_concept/chuc/\", \"../lib/data/raw/source_to_concept/hds/\"]\n",
    "concept_vocab = \"../lib/data/raw/vocabularies/CONCEPT.csv\"\n",
    "\n",
    "rdp = RawDataProcessor(vocab_file=concept_vocab, hospital_folders=hospital_folders)\n",
    "sources, targets = rdp.join_source_target()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sources, targets = rdp._prepare_4_encoding(sources, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sources) == len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2222"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dict = dict(zip(range(len(sources)), sources))\n",
    "target_dict = dict(zip(range(len(targets)), targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('../lib/artifacts/dicts/sources.pickle', 'wb') as handle:\n",
    "    pickle.dump(source_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('../lib/artifacts/dicts/targets.pickle', 'wb') as handle:\n",
    "    pickle.dump(target_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selected models and why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_models = [ \n",
    "                  \"mixedbread-ai/mxbai-embed-large-v1\",\n",
    "                  'intfloat/multilingual-e5-small',\n",
    "                  \"intfloat/multilingual-e5-base\", \n",
    "                  \"intfloat/multilingual-e5-large\", \n",
    "                  \"sentence-transformers/all-MiniLM-L6-v2\", \n",
    "                  # \"Henrychur/MMedLM2\", # too large for now\n",
    "                  \"medicalai/ClinicalBERT\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from time import time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "def test_models(models: list, sources: list, targets: list):\n",
    "\n",
    "    # Store results\n",
    "    results_df = []\n",
    "    results = []\n",
    "\n",
    "    for plm in tqdm(models, desc=\"Testing models: \"):\n",
    "\n",
    "        # Load model\n",
    "        needs_remote_code = 0\n",
    "        try:\n",
    "            model = SentenceTransformer(plm, trust_remote_code=False)\n",
    "        except ValueError:\n",
    "            model = SentenceTransformer(plm, trust_remote_code=True)\n",
    "            needs_remote_code = 1\n",
    "        \n",
    "        for query_prefix in ['', 'query: ']:\n",
    "\n",
    "            mod_sources = [(query_prefix + i) for i in sources]\n",
    "            mod_targets = [(query_prefix + i) for i in targets]\n",
    "\n",
    "            # Track results\n",
    "            top1 = 0\n",
    "            top5 = 0\n",
    "            top10 = 0\n",
    "            total = len(sources)\n",
    "\n",
    "            # Encode\n",
    "            sources_emb = model.encode(mod_sources, normalize_embeddings=True)\n",
    "            targets_emb = model.encode(mod_targets, normalize_embeddings=True)\n",
    "\n",
    "            # Track Encoding Time\n",
    "            start = time()\n",
    "            for i in tqdm(range(total), leave=False):\n",
    "\n",
    "                # Compute distances\n",
    "                source_example = sources_emb[i]\n",
    "                distance, index = norml2_innerproduct(targets_emb, source_example)\n",
    "\n",
    "                # Check matches\n",
    "                if i == index[0][0]:\n",
    "                    top1 += 1\n",
    "                    top5 += 1\n",
    "                    top10 += 1\n",
    "                elif i in index[0][:5]:\n",
    "                    top5 += 1\n",
    "                    top10 += 1\n",
    "                elif i in index[0][:10]:\n",
    "                    top10 += 1\n",
    "\n",
    "            # Compute time\n",
    "            end = time()\n",
    "            elapsed_seconds = end - start\n",
    "\n",
    "            results_df.append(\n",
    "                {   \n",
    "                    \"plm\": plm + '__query_prefix__' + query_prefix,\n",
    "                    \"remote_code\": needs_remote_code,\n",
    "                    \"Top-1 match\": top1/total,\n",
    "                    \"Top-5 match\": top5/total,\n",
    "                    \"Top-10 match\": top10/total,\n",
    "                    \"Total number of tests\": len(sources),\n",
    "                    \"Elapsed seconds\": elapsed_seconds,\n",
    "                    \"Predictions per second X 1000\": len(sources)/elapsed_seconds/1000\n",
    "                }\n",
    "            )\n",
    "\n",
    "            results.append(f\"\"\"\n",
    "                            plm: {plm + '__query_prefix__' + query_prefix};\n",
    "                            needs remote code: {needs_remote_code};\n",
    "                            Top 1 match: {top1/total:.2%};\n",
    "                            Top 5 match: {top5/total:.2%};\n",
    "                            Top 10 match: {top10/total:.2%};\n",
    "                            Total number of tests: {len(sources)},\n",
    "                            Elapsed seconds: {elapsed_seconds};\n",
    "                            Predictions per second X 1000: {len(sources)/elapsed_seconds/1000:.2}\n",
    "                            \"\"\")\n",
    "        \n",
    "    [print(_) for _ in results]\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models:  83%|████████▎ | 5/6 [02:19<00:25, 25.05s/it]No sentence-transformers model found with name medicalai/ClinicalBERT. Creating a new one with MEAN pooling.\n",
      "Testing models: 100%|██████████| 6/6 [02:32<00:00, 25.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                            plm: mixedbread-ai/mxbai-embed-large-v1__query_prefix__;\n",
      "                            needs remote code: 0;\n",
      "                            Top 1 match: 47.97%;\n",
      "                            Top 5 match: 75.92%;\n",
      "                            Top 10 match: 82.40%;\n",
      "                            Total number of tests: 2222,\n",
      "                            Elapsed seconds: 2.1125829219818115;\n",
      "                            Predictions per second X 1000: 1.1\n",
      "                            \n",
      "\n",
      "                            plm: mixedbread-ai/mxbai-embed-large-v1__query_prefix__query: ;\n",
      "                            needs remote code: 0;\n",
      "                            Top 1 match: 46.71%;\n",
      "                            Top 5 match: 73.54%;\n",
      "                            Top 10 match: 80.69%;\n",
      "                            Total number of tests: 2222,\n",
      "                            Elapsed seconds: 2.0437729358673096;\n",
      "                            Predictions per second X 1000: 1.1\n",
      "                            \n",
      "\n",
      "                            plm: intfloat/multilingual-e5-small__query_prefix__;\n",
      "                            needs remote code: 0;\n",
      "                            Top 1 match: 48.42%;\n",
      "                            Top 5 match: 71.47%;\n",
      "                            Top 10 match: 77.59%;\n",
      "                            Total number of tests: 2222,\n",
      "                            Elapsed seconds: 1.1938669681549072;\n",
      "                            Predictions per second X 1000: 1.9\n",
      "                            \n",
      "\n",
      "                            plm: intfloat/multilingual-e5-small__query_prefix__query: ;\n",
      "                            needs remote code: 0;\n",
      "                            Top 1 match: 47.97%;\n",
      "                            Top 5 match: 71.87%;\n",
      "                            Top 10 match: 78.49%;\n",
      "                            Total number of tests: 2222,\n",
      "                            Elapsed seconds: 1.1872057914733887;\n",
      "                            Predictions per second X 1000: 1.9\n",
      "                            \n",
      "\n",
      "                            plm: intfloat/multilingual-e5-base__query_prefix__;\n",
      "                            needs remote code: 0;\n",
      "                            Top 1 match: 47.16%;\n",
      "                            Top 5 match: 71.02%;\n",
      "                            Top 10 match: 77.77%;\n",
      "                            Total number of tests: 2222,\n",
      "                            Elapsed seconds: 2.076834201812744;\n",
      "                            Predictions per second X 1000: 1.1\n",
      "                            \n",
      "\n",
      "                            plm: intfloat/multilingual-e5-base__query_prefix__query: ;\n",
      "                            needs remote code: 0;\n",
      "                            Top 1 match: 46.94%;\n",
      "                            Top 5 match: 69.31%;\n",
      "                            Top 10 match: 76.37%;\n",
      "                            Total number of tests: 2222,\n",
      "                            Elapsed seconds: 2.0491340160369873;\n",
      "                            Predictions per second X 1000: 1.1\n",
      "                            \n",
      "\n",
      "                            plm: intfloat/multilingual-e5-large__query_prefix__;\n",
      "                            needs remote code: 0;\n",
      "                            Top 1 match: 50.05%;\n",
      "                            Top 5 match: 74.30%;\n",
      "                            Top 10 match: 80.56%;\n",
      "                            Total number of tests: 2222,\n",
      "                            Elapsed seconds: 2.070066213607788;\n",
      "                            Predictions per second X 1000: 1.1\n",
      "                            \n",
      "\n",
      "                            plm: intfloat/multilingual-e5-large__query_prefix__query: ;\n",
      "                            needs remote code: 0;\n",
      "                            Top 1 match: 50.90%;\n",
      "                            Top 5 match: 73.31%;\n",
      "                            Top 10 match: 79.30%;\n",
      "                            Total number of tests: 2222,\n",
      "                            Elapsed seconds: 2.759983777999878;\n",
      "                            Predictions per second X 1000: 0.81\n",
      "                            \n",
      "\n",
      "                            plm: sentence-transformers/all-MiniLM-L6-v2__query_prefix__;\n",
      "                            needs remote code: 0;\n",
      "                            Top 1 match: 41.45%;\n",
      "                            Top 5 match: 68.23%;\n",
      "                            Top 10 match: 75.43%;\n",
      "                            Total number of tests: 2222,\n",
      "                            Elapsed seconds: 1.145369052886963;\n",
      "                            Predictions per second X 1000: 1.9\n",
      "                            \n",
      "\n",
      "                            plm: sentence-transformers/all-MiniLM-L6-v2__query_prefix__query: ;\n",
      "                            needs remote code: 0;\n",
      "                            Top 1 match: 39.69%;\n",
      "                            Top 5 match: 65.44%;\n",
      "                            Top 10 match: 72.50%;\n",
      "                            Total number of tests: 2222,\n",
      "                            Elapsed seconds: 1.1557071208953857;\n",
      "                            Predictions per second X 1000: 1.9\n",
      "                            \n",
      "\n",
      "                            plm: medicalai/ClinicalBERT__query_prefix__;\n",
      "                            needs remote code: 0;\n",
      "                            Top 1 match: 28.53%;\n",
      "                            Top 5 match: 46.62%;\n",
      "                            Top 10 match: 52.75%;\n",
      "                            Total number of tests: 2222,\n",
      "                            Elapsed seconds: 2.070725202560425;\n",
      "                            Predictions per second X 1000: 1.1\n",
      "                            \n",
      "\n",
      "                            plm: medicalai/ClinicalBERT__query_prefix__query: ;\n",
      "                            needs remote code: 0;\n",
      "                            Top 1 match: 25.56%;\n",
      "                            Top 5 match: 42.12%;\n",
      "                            Top 10 match: 48.96%;\n",
      "                            Total number of tests: 2222,\n",
      "                            Elapsed seconds: 2.039607048034668;\n",
      "                            Predictions per second X 1000: 1.1\n",
      "                            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_df = test_models(list_of_models, sources, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "usagis = {\"plm\": 'USAGI', \"Top-1 match\": 0.42, \"Top-5 match\": 0.58, \"Top-10 match\": 0.62} # From toki paper\n",
    "results_df.append(usagis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plm</th>\n",
       "      <th>remote_code</th>\n",
       "      <th>Top-1 match</th>\n",
       "      <th>Top-5 match</th>\n",
       "      <th>Top-10 match</th>\n",
       "      <th>Total number of tests</th>\n",
       "      <th>Elapsed seconds</th>\n",
       "      <th>Predictions per second X 1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mixedbread-ai/mxbai-embed-large-v1__query_pref...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.479748</td>\n",
       "      <td>0.759226</td>\n",
       "      <td>0.824032</td>\n",
       "      <td>2222.0</td>\n",
       "      <td>2.112583</td>\n",
       "      <td>1.051793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mixedbread-ai/mxbai-embed-large-v1__query_pref...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.467147</td>\n",
       "      <td>0.735374</td>\n",
       "      <td>0.806931</td>\n",
       "      <td>2222.0</td>\n",
       "      <td>2.043773</td>\n",
       "      <td>1.087205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>intfloat/multilingual-e5-small__query_prefix__</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484248</td>\n",
       "      <td>0.714671</td>\n",
       "      <td>0.775878</td>\n",
       "      <td>2222.0</td>\n",
       "      <td>1.193867</td>\n",
       "      <td>1.861179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>intfloat/multilingual-e5-small__query_prefix__...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.479748</td>\n",
       "      <td>0.718722</td>\n",
       "      <td>0.784878</td>\n",
       "      <td>2222.0</td>\n",
       "      <td>1.187206</td>\n",
       "      <td>1.871622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>intfloat/multilingual-e5-base__query_prefix__</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.471647</td>\n",
       "      <td>0.710171</td>\n",
       "      <td>0.777678</td>\n",
       "      <td>2222.0</td>\n",
       "      <td>2.076834</td>\n",
       "      <td>1.069898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>intfloat/multilingual-e5-base__query_prefix__q...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469397</td>\n",
       "      <td>0.693069</td>\n",
       "      <td>0.763726</td>\n",
       "      <td>2222.0</td>\n",
       "      <td>2.049134</td>\n",
       "      <td>1.084361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>intfloat/multilingual-e5-large__query_prefix__</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500450</td>\n",
       "      <td>0.743024</td>\n",
       "      <td>0.805581</td>\n",
       "      <td>2222.0</td>\n",
       "      <td>2.070066</td>\n",
       "      <td>1.073396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>intfloat/multilingual-e5-large__query_prefix__...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.509001</td>\n",
       "      <td>0.733123</td>\n",
       "      <td>0.792979</td>\n",
       "      <td>2222.0</td>\n",
       "      <td>2.759984</td>\n",
       "      <td>0.805077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2__query_...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.414491</td>\n",
       "      <td>0.682268</td>\n",
       "      <td>0.754275</td>\n",
       "      <td>2222.0</td>\n",
       "      <td>1.145369</td>\n",
       "      <td>1.939986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2__query_...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.396940</td>\n",
       "      <td>0.654365</td>\n",
       "      <td>0.725023</td>\n",
       "      <td>2222.0</td>\n",
       "      <td>1.155707</td>\n",
       "      <td>1.922632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>medicalai/ClinicalBERT__query_prefix__</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285329</td>\n",
       "      <td>0.466247</td>\n",
       "      <td>0.527453</td>\n",
       "      <td>2222.0</td>\n",
       "      <td>2.070725</td>\n",
       "      <td>1.073054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>medicalai/ClinicalBERT__query_prefix__query:</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255626</td>\n",
       "      <td>0.421242</td>\n",
       "      <td>0.489649</td>\n",
       "      <td>2222.0</td>\n",
       "      <td>2.039607</td>\n",
       "      <td>1.089426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>USAGI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  plm  remote_code  \\\n",
       "0   mixedbread-ai/mxbai-embed-large-v1__query_pref...          0.0   \n",
       "1   mixedbread-ai/mxbai-embed-large-v1__query_pref...          0.0   \n",
       "2      intfloat/multilingual-e5-small__query_prefix__          0.0   \n",
       "3   intfloat/multilingual-e5-small__query_prefix__...          0.0   \n",
       "4       intfloat/multilingual-e5-base__query_prefix__          0.0   \n",
       "5   intfloat/multilingual-e5-base__query_prefix__q...          0.0   \n",
       "6      intfloat/multilingual-e5-large__query_prefix__          0.0   \n",
       "7   intfloat/multilingual-e5-large__query_prefix__...          0.0   \n",
       "8   sentence-transformers/all-MiniLM-L6-v2__query_...          0.0   \n",
       "9   sentence-transformers/all-MiniLM-L6-v2__query_...          0.0   \n",
       "10             medicalai/ClinicalBERT__query_prefix__          0.0   \n",
       "11      medicalai/ClinicalBERT__query_prefix__query:           0.0   \n",
       "12                                              USAGI          NaN   \n",
       "\n",
       "    Top-1 match  Top-5 match  Top-10 match  Total number of tests  \\\n",
       "0      0.479748     0.759226      0.824032                 2222.0   \n",
       "1      0.467147     0.735374      0.806931                 2222.0   \n",
       "2      0.484248     0.714671      0.775878                 2222.0   \n",
       "3      0.479748     0.718722      0.784878                 2222.0   \n",
       "4      0.471647     0.710171      0.777678                 2222.0   \n",
       "5      0.469397     0.693069      0.763726                 2222.0   \n",
       "6      0.500450     0.743024      0.805581                 2222.0   \n",
       "7      0.509001     0.733123      0.792979                 2222.0   \n",
       "8      0.414491     0.682268      0.754275                 2222.0   \n",
       "9      0.396940     0.654365      0.725023                 2222.0   \n",
       "10     0.285329     0.466247      0.527453                 2222.0   \n",
       "11     0.255626     0.421242      0.489649                 2222.0   \n",
       "12     0.420000     0.580000      0.620000                    NaN   \n",
       "\n",
       "    Elapsed seconds  Predictions per second X 1000  \n",
       "0          2.112583                       1.051793  \n",
       "1          2.043773                       1.087205  \n",
       "2          1.193867                       1.861179  \n",
       "3          1.187206                       1.871622  \n",
       "4          2.076834                       1.069898  \n",
       "5          2.049134                       1.084361  \n",
       "6          2.070066                       1.073396  \n",
       "7          2.759984                       0.805077  \n",
       "8          1.145369                       1.939986  \n",
       "9          1.155707                       1.922632  \n",
       "10         2.070725                       1.073054  \n",
       "11         2.039607                       1.089426  \n",
       "12              NaN                            NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "res_df = pd.DataFrame.from_dict(results_df)\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plm</th>\n",
       "      <th>remote_code</th>\n",
       "      <th>Top-1 match</th>\n",
       "      <th>Top-5 match</th>\n",
       "      <th>Top-10 match</th>\n",
       "      <th>Total number of tests</th>\n",
       "      <th>Elapsed seconds</th>\n",
       "      <th>Predictions per second X 1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mixedbread-ai/mxbai-embed-large-v1__query_pref...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.479748</td>\n",
       "      <td>0.759226</td>\n",
       "      <td>0.824032</td>\n",
       "      <td>2222.0</td>\n",
       "      <td>2.112583</td>\n",
       "      <td>1.051793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mixedbread-ai/mxbai-embed-large-v1__query_pref...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.467147</td>\n",
       "      <td>0.735374</td>\n",
       "      <td>0.806931</td>\n",
       "      <td>2222.0</td>\n",
       "      <td>2.043773</td>\n",
       "      <td>1.087205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>intfloat/multilingual-e5-small__query_prefix__</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484248</td>\n",
       "      <td>0.714671</td>\n",
       "      <td>0.775878</td>\n",
       "      <td>2222.0</td>\n",
       "      <td>1.193867</td>\n",
       "      <td>1.861179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>intfloat/multilingual-e5-small__query_prefix__...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.479748</td>\n",
       "      <td>0.718722</td>\n",
       "      <td>0.784878</td>\n",
       "      <td>2222.0</td>\n",
       "      <td>1.187206</td>\n",
       "      <td>1.871622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>intfloat/multilingual-e5-base__query_prefix__</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.471647</td>\n",
       "      <td>0.710171</td>\n",
       "      <td>0.777678</td>\n",
       "      <td>2222.0</td>\n",
       "      <td>2.076834</td>\n",
       "      <td>1.069898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>intfloat/multilingual-e5-base__query_prefix__q...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469397</td>\n",
       "      <td>0.693069</td>\n",
       "      <td>0.763726</td>\n",
       "      <td>2222.0</td>\n",
       "      <td>2.049134</td>\n",
       "      <td>1.084361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>intfloat/multilingual-e5-large__query_prefix__</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500450</td>\n",
       "      <td>0.743024</td>\n",
       "      <td>0.805581</td>\n",
       "      <td>2222.0</td>\n",
       "      <td>2.070066</td>\n",
       "      <td>1.073396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>intfloat/multilingual-e5-large__query_prefix__...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.509001</td>\n",
       "      <td>0.733123</td>\n",
       "      <td>0.792979</td>\n",
       "      <td>2222.0</td>\n",
       "      <td>2.759984</td>\n",
       "      <td>0.805077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>USAGI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  plm  remote_code  \\\n",
       "0   mixedbread-ai/mxbai-embed-large-v1__query_pref...          0.0   \n",
       "1   mixedbread-ai/mxbai-embed-large-v1__query_pref...          0.0   \n",
       "2      intfloat/multilingual-e5-small__query_prefix__          0.0   \n",
       "3   intfloat/multilingual-e5-small__query_prefix__...          0.0   \n",
       "4       intfloat/multilingual-e5-base__query_prefix__          0.0   \n",
       "5   intfloat/multilingual-e5-base__query_prefix__q...          0.0   \n",
       "6      intfloat/multilingual-e5-large__query_prefix__          0.0   \n",
       "7   intfloat/multilingual-e5-large__query_prefix__...          0.0   \n",
       "12                                              USAGI          NaN   \n",
       "\n",
       "    Top-1 match  Top-5 match  Top-10 match  Total number of tests  \\\n",
       "0      0.479748     0.759226      0.824032                 2222.0   \n",
       "1      0.467147     0.735374      0.806931                 2222.0   \n",
       "2      0.484248     0.714671      0.775878                 2222.0   \n",
       "3      0.479748     0.718722      0.784878                 2222.0   \n",
       "4      0.471647     0.710171      0.777678                 2222.0   \n",
       "5      0.469397     0.693069      0.763726                 2222.0   \n",
       "6      0.500450     0.743024      0.805581                 2222.0   \n",
       "7      0.509001     0.733123      0.792979                 2222.0   \n",
       "12     0.420000     0.580000      0.620000                    NaN   \n",
       "\n",
       "    Elapsed seconds  Predictions per second X 1000  \n",
       "0          2.112583                       1.051793  \n",
       "1          2.043773                       1.087205  \n",
       "2          1.193867                       1.861179  \n",
       "3          1.187206                       1.871622  \n",
       "4          2.076834                       1.069898  \n",
       "5          2.049134                       1.084361  \n",
       "6          2.070066                       1.073396  \n",
       "7          2.759984                       0.805077  \n",
       "12              NaN                            NaN  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = res_df.loc[\n",
    "    (res_df['Top-1 match'] >= usagis['Top-1 match']) &\n",
    "    (res_df['Top-5 match'] >= usagis['Top-5 match']) &\n",
    "    (res_df['Top-10 match'] >= usagis['Top-10 match']), :]\n",
    "\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "dimensions": [
          {
           "constraintrange": [
            0.42,
            0.509000900090009
           ],
           "label": "Top-1 match",
           "range": [
            0.42,
            0.509000900090009
           ],
           "values": [
            0.4671467146714671,
            0.48424842484248426,
            0.47974797479747977,
            0.47164716471647167,
            0.4693969396939694,
            0.5004500450045004,
            0.509000900090009,
            0.42
           ]
          },
          {
           "constraintrange": [
            0.58,
            0.743024302430243
           ],
           "label": "Top-5 match",
           "range": [
            0.58,
            0.743024302430243
           ],
           "values": [
            0.7353735373537353,
            0.7146714671467147,
            0.7187218721872187,
            0.7101710171017102,
            0.693069306930693,
            0.743024302430243,
            0.7331233123312331,
            0.58
           ]
          },
          {
           "constraintrange": [
            0.62,
            0.806930693069307
           ],
           "label": "Top-10 match",
           "range": [
            0.62,
            0.806930693069307
           ],
           "values": [
            0.806930693069307,
            0.7758775877587759,
            0.7848784878487849,
            0.7776777677767777,
            0.7637263726372637,
            0.8055805580558055,
            0.7929792979297929,
            0.62
           ]
          },
          {
           "constraintrange": [
            0,
            1.8716215975011155
           ],
           "label": "Predictions per second X 1000",
           "range": [
            0,
            1.8716215975011155
           ],
           "values": [
            1.087204924287275,
            1.8611788911741547,
            1.8716215975011155,
            1.069897634611636,
            1.084360506736077,
            1.073395616716731,
            0.8050771956385383,
            0
           ]
          },
          {
           "label": "plm",
           "range": [
            0,
            7
           ],
           "ticktext": [
            "mixedbread-ai/mxbai-embed-large-v1__query_prefix__query: ",
            "intfloat/multilingual-e5-small__query_prefix__",
            "intfloat/multilingual-e5-small__query_prefix__query: ",
            "intfloat/multilingual-e5-base__query_prefix__",
            "intfloat/multilingual-e5-base__query_prefix__query: ",
            "intfloat/multilingual-e5-large__query_prefix__",
            "intfloat/multilingual-e5-large__query_prefix__query: ",
            "USAGI"
           ],
           "tickvals": [
            0,
            1,
            2,
            3,
            4,
            5,
            6,
            7
           ],
           "values": [
            0,
            1,
            2,
            3,
            4,
            5,
            6,
            7
           ]
          }
         ],
         "line": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7
          ],
          "colorscale": [
           [
            0,
            "rgba(99,110,250,0.9)"
           ],
           [
            0.1111111111111111,
            "rgba(239,85,59,0.9)"
           ],
           [
            0.2222222222222222,
            "rgba(0,204,150,0.9)"
           ],
           [
            0.3333333333333333,
            "rgba(171,99,250,0.9)"
           ],
           [
            0.4444444444444444,
            "rgba(255,161,90,0.9)"
           ],
           [
            0.5555555555555556,
            "rgba(25,211,243,0.9)"
           ],
           [
            0.6666666666666666,
            "rgba(255,102,146,0.9)"
           ],
           [
            0.7777777777777778,
            "rgba(182,232,128,0.9)"
           ],
           [
            0.8888888888888888,
            "rgba(255,151,255,0.9)"
           ],
           [
            1,
            "rgba(254,203,82,0.9)"
           ]
          ]
         },
         "type": "parcoords"
        }
       ],
       "layout": {
        "font": {
         "color": "Black",
         "family": "Sans-serif",
         "size": 13
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "def parallel(df):\n",
    "    df = df.fillna(0)\n",
    "    df['dummy'] = df.reset_index().index\n",
    "    dimensions = list([\n",
    "                dict(range = [min(df['Top-1 match']),max(df['Top-1 match'])],\n",
    "                    constraintrange = [min(df['Top-1 match']),max(df['Top-1 match'])],\n",
    "                    label = 'Top-1 match', values = df['Top-1 match']),\n",
    "                dict(range = [min(df['Top-5 match']),max(df['Top-5 match'])],\n",
    "                    constraintrange = [min(df['Top-5 match']),max(df['Top-5 match'])],\n",
    "                    label = 'Top-5 match', values = df['Top-5 match']),\n",
    "                dict(range = [min(df['Top-10 match']),max(df['Top-10 match'])],\n",
    "                    constraintrange = [min(df['Top-10 match']),max(df['Top-10 match'])],\n",
    "                    label = 'Top-10 match', values = df['Top-10 match']),\n",
    "                dict(range = [min(df['Predictions per second X 1000']),max(df['Predictions per second X 1000'])],\n",
    "                    constraintrange = [min(df['Predictions per second X 1000']),max(df['Predictions per second X 1000'])],\n",
    "                    label = 'Predictions per second X 1000', values = df['Predictions per second X 1000']),\n",
    "                dict(range=[df['dummy'].min(),df['dummy'].max()],\n",
    "                       tickvals = df['dummy'], ticktext = df['plm'],\n",
    "                       label='plm', values=df['dummy']),\n",
    "                  ])\n",
    "\n",
    "    fig = go.Figure(data=go.Parcoords(line = dict(color = df['dummy'], colorscale=['rgba(99,110,250,0.9)',\n",
    "    'rgba(239,85,59,0.9)',\n",
    "    'rgba(0,204,150,0.9)',\n",
    "    'rgba(171,99,250,0.9)',\n",
    "    'rgba(255,161,90,0.9)',\n",
    "    'rgba(25,211,243,0.9)',\n",
    "    'rgba(255,102,146,0.9)',\n",
    "    'rgba(182,232,128,0.9)',\n",
    "    'rgba(255,151,255,0.9)',\n",
    "    'rgba(254,203,82,0.9)']\n",
    "                    ), dimensions=dimensions))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        font=dict(\n",
    "            family=\"Sans-serif\",\n",
    "            size=13,\n",
    "            color=\"Black\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parallel(res_df[1:])         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vocab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
